!obj:pylearn2.train.Train {
    dataset: &train !obj:pylearn2.datasets.mnist.MNIST {
        which_set: 'train',
        start: 0,
        stop: 50000
    },
    model: !obj:CAN.CompressAdversaryPair {
        compressor: !obj:CAN.compressor {
            mlp: !pkl: "%(DATA_DIR)s/AE_experiments/models/D17/solotrain.pkl"
        },
        discriminator: !pkl: "%(DATA_DIR)s/CAN_experiments/models/CAN_B1-b/CAN_B1-b.pkl.dis"
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
        batch_size: 100,
        learning_rate: 0.1,
        learning_rule: 
            !obj:pylearn2.training_algorithms.learning_rule.Momentum {
                init_momentum: 0
            },
        monitoring_dataset:
            {
                'valid' : !obj:pylearn2.datasets.mnist.MNIST {
                              which_set: 'train',
                              start: 50000,
                              stop:  60000
                          },
            },
        cost: !obj:CAN.AdversaryCost_A {
            init_train_clock: 1,
            discriminator_steps: 0,
            joint_steps: 1,
            compressor_steps: 0,
            ever_train_compressor: 1,
            ever_train_discriminator: 1
            },

        update_callbacks: !obj:pylearn2.training_algorithms.sgd.ExponentialDecay {
            decay_factor: 1.0,
            min_lr: 0.01
        }
    },
    extensions: [
        #!obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
        #     channel_name: 'valid_y_misclass',
        #     save_path: "${PYLEARN2_TRAIN_FILE_FULL_STEM}_best.pkl"
        #},
        !obj:pylearn2.training_algorithms.learning_rule.MomentumAdjustor {
            start: 1,
            saturate: 250,
            final_momentum: 0
        },
        !obj:CAN.save_pieces {
            save_path: "%(SAVE_PATH)s"
        }
    ]
}
